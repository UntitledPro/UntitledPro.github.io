{"pages":[],"posts":[{"title":"BlogTemplates","text":"这里是简介.jpg Content window.changyan.api.config({ appid: 'cyvoWBcYh', conf: 'prod_82fb399b42af278fa503f42fe4c11ab1' });","link":"/2021/03/17/BlogTemplate/"},{"title":"【Issue】：博客无法正确显示图床图片（Failed to load resource net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH）","text":"使用了七牛云做图床，这样引用图片的时候可以直接输入url，CDN也加快了网站加载速度。但是当博客上传后，图片却无法正常显示，url链接是没问题的 问题使用了七牛云做图床，这样引用图片的时候可以直接输入url，CDN也加快了网站加载速度。但是当博客上传后，图片却无法正常显示，url链接是没问题的 原因emmm，只是可能原因，因为我没有买一级域名，所以..也不太知道 这篇CSDN博客遇到了同样的问题 文中提到，之所以无法显示，是因为该图片的域名没有通过证书认证，在谷歌浏览器里面不被信任，从而导致了图片无法被正常显示的问题 解决办法 置一个有效的本地开发server的证书，并将证书添加信任，参考使用OpenSSL生成多域名自签名证书进行HTTPS开发调试 - 知乎专栏有(you)机(qian)会(le)试一试（；´д｀）ゞ 这篇博客比较详细的介绍了如何解决ERR_SSL_VERSION_OR_CIPHER_MISMATCH 问题 window.changyan.api.config({ appid: 'cyvoWBcYh', conf: 'prod_82fb399b42af278fa503f42fe4c11ab1' });","link":"/2021/04/15/PicIssue/"},{"title":"blog","text":"什么也没有.jpg 一些代码过程中的总结 nn.Parameter(requires_grad=True)和torch.Tensor(requires_grad=True)的功能是相同的，都是创建了一个可学习的向量，但是不同之处在于，nn.Parameter所创建的是一个nn.Module的子类，就像是nn.layer一样，是包含在模型结构中的，但是torch.Tensor只是创建了一个向量 之所以经常用tensor.view()而非tensor.reshape，是因为view实在原有 tensor 上操作，不会占用多余的内存，而 reshape 是创建一个新的 tensor 在大量使用reshape 的情况下，可能会导致内存不足 window.changyan.api.config({ appid: 'cyvoWBcYh', conf: 'prod_82fb399b42af278fa503f42fe4c11ab1' });","link":"/2021/03/18/blog/"},{"title":"【数据集】：miniImageNet","text":"说明目前可用标签 Essay DataSets Pytorch Literature review 可用目录 Pytorch Dataset Python Paper notes DeepLearning Dataset Essay window.changyan.api.config({ appid: 'cyvoWBcYh', conf: 'prod_82fb399b42af278fa503f42fe4c11ab1' });","link":"/2021/04/14/miniImageNet/"},{"title":"【python】：生成器(generator)详解","text":"介绍python中的生成器 1 生成器(generator)在Python中，一边循环一边计算的机制，称为生成器：generator。 1.1 为什么使用生成器列表所有数据都在内存中，如果有海量数据的话将会非常耗内存。 如：仅仅需要访问前面几个元素，那后面绝大多数元素占用的空间都白白浪费了。 对于需要访问大数据集更是如此 如果列表元素按照某种算法推算出来，那我们就可以在循环的过程中不断推算出后续的元素，这样就不必创建完整的list，从而节省大量的空间。 简单一句话：又想要得到庞大的数据，又想让它占用空间少，那就用生成器. 1.2 创建生成器(introduce)1.2.1 简单示例123456789101112131415161718# 列表生成式lis = [x*x for x in range(10)]# &gt;&gt; [0, 1, 2, 3..., 9, 10]# 生成器# 生成器表达式：返回一个对象，这个对象只有在需要的时候才产生结果generator_ex = (x*x for x in range(10))# &gt;&gt; &lt;generator object &lt;genexpr&gt; at 0x000002A4CBF9EBA0&gt;# 生成器# 生成器函数：也是用def定义的，利用关键字yield一次性返回一个结果，阻塞，重新开始def fib(max): n,a,b =0,0,1 while n &lt; max: yield b a,b =b,a+b n = n+1 return 'done' 1.2.2 生成器函数生成器函数会随着时间的推移生成一个数值队列。一般的函数在执行完毕之后会返回一个值然后退出，但是生成器函数会自动挂起，然后重新拾起继续执行，他会利用yield关键字挂起函数，给调用者返回一个值，同时保留了当前的足够多的状态，可以使函数继续执行。 生成器和迭代协议是密切相关的，迭代器都有一个__next__()__成员方法，这个方法要么返回迭代的下一项，要么引起异常结束迭代。 12345678910111213141516171819202122# 函数有了yield之后，函数名+（）就变成了生成器# return在生成器中代表生成器的中止，直接报错# next的作用是唤醒并继续执行# send的作用是唤醒并继续执行，发送一个信息到生成器内部'''生成器'''def create_counter(n): print(&quot;create_counter&quot;) while True: yield n print(&quot;increment n&quot;) n +=1gen = create_counter(2)print(gen)# &lt;generator object create_counter at 0x0000023A1694A938&gt;print(next(gen))# create_counter# 2print(next(gen))# increment n# 3 1.2.3 生成器表达式生成器表达式来源于迭代和列表解析的组合，生成器和列表解析类似，但是它使用尖括号而不是方括号 1234567891011# 列表解析生成列表[ x ** 3 for x in range(5)]# &gt;&gt; [0, 1, 8, 27, 64]# 生成器表达式(x ** 3 for x in range(5))# &gt;&gt; &lt;generator object &lt;genexpr&gt; at 0x000000000315F678&gt;# 两者之间转换list(x ** 3 for x in range(5))# &gt;&gt; [0, 1, 8, 27, 64] 1.2.2 使用1.2.2.1 next()1234567def consumer(): r = 0 for i in xrange(3): # next 运行到这里结束 yield r # 第n(n&gt;1)次调用next时，从这里开始 r = '200 OK'+ str(i) 第一个next调用，相当于启动生成器，会从生成器函数的第一行代码开始执行，直到第一次执行完yield语句后，跳出生成器函数。 然后第二个next调用，进入生成器函数后，从yield语句的下一句语句开始执行，然后重新运行到yield语句。执行后，跳出生成器函数。 后面再次调用next，则依次类推。 next 的小问题generator保存的是算法，每次调用next(generaotr_ex)就计算出他的下一个元素的值，直到计算出最后一个元素，没有更多的元素时，抛出StopIteration的错误，而且不断调用是一个不好的习惯，正确的方法是使用for循环，因为generator也是可迭代对象。 123456789101112generator_ex = (x*x for x in range(10))print(next(generator_ex))# ...print(next(generator_ex))# Traceback (most recent call last):# File &quot;列表生成式.py&quot;, line 42, in &lt;module&gt;# print(next(generator_ex))# StopIteration 1.2.2.2 send(args)generator.next()，一定程度上等价于generator.send(None) 12345678910111213def consumer(): r = 'here' while True: n1 = yield r if not n1: return print('[CONSUMER] Consuming %s...' % n1) r = '%d00 OK' % n1c = consumer()c.send(None)c.send(1)c.send(2) 注意，n1 = yield r是从右向左执行。 第一次调用c.send(None)时，当yield r执行完毕后，是并没有将r赋值给n1的，此时，只是返回了r = 'here' 第二次调用c.send(1)时，将继续执行n1 = yield r，并将1赋值给n1，下面继续从yield的下一语句继续执行，然后重新运行到yield语句并跳出。 简单来看，send和next相比，只是开始多了一次赋值的动作，其他运行流程是相同的。 1.2.2.3 for123generator_ex = (x * x for x in range(10))for i in generator_ex: print(i) generator保存的是算法，每次调用next(generaotr_ex)就计算出他的下一个元素的值，直到计算出最后一个元素，没有更多的元素时，抛出StopIteration的错误，而且不断调用是一个不好的习惯，正确的方法是使用for循环，因为generator也是可迭代对象。 for 小问题所以当创建一个generator后，基本上永远不会调用next()，而是通过for循环来迭代，并且不需要关心StopIteration的错误，generator非常强大，如果推算的算法比较复杂，用类似列表生成式的for循环无法实现的时候，还可以用函数来实现。如在1.2.2 生成器函数中所创建的生成器函数 12345678910def fib(max): n,a,b =0,0,1 while n &lt; max: yield b a,b =b,a+b n = n+1 return 'done'for i in fib(6): print(i) 但是用for循环调用generator fib()时，发现拿不到generator的return语句的返回值。如果拿不到返回值，那么就会报错，所以需要进行异常处理，拿到返回值，如果想要拿到返回值，必须捕获StopIteration错误，返回值包含在StopIteration的value中： 123456789101112131415161718def fib(max): n,a,b =0,0,1 while n &lt; max: yield b a,b =b,a+b n = n+1 return 'done'g = fib(6)while True: try: x = next(g) print('generator: ',x) except StopIteration as e: # 返回值 包含在StopIteration的value中 print(&quot;生成器返回值：&quot;,e.value) break window.changyan.api.config({ appid: 'cyvoWBcYh', conf: 'prod_82fb399b42af278fa503f42fe4c11ab1' });","link":"/2021/04/15/python-generator/"},{"title":"【python】：迭代器相关概念汇总（容器，迭代器，生成器）","text":"介绍python中 iterable 的相关概念，包括 container，iterable，iterator，generator Container, Iterator, generator 之间的关系如下: 1. ContainerContainer 是存储数据的数据结构，同时也支持成员检索。Container 的所有数据都是储存在内存中的。一些常见的 Container有： list set dict tuple str … Container 很容易理解，你可以把它想象为现实生活中的容器，比如盒子，房屋，橱柜等等。 当可以询问对象是否包含某个元素时，它就是一个容器。可以对 list、set 或 tuple 执行此类成员资格测试： 1234567# list# 1 不在 [1,2,3]中时报错...assert 1 in [1, 2, 3]assert 4 not in [1, 2, 3]# setassert 1 in {1, 2, 3}assert 4 not in {1, 2, 3} 对于字典： 1234d = {1: 'a', 2: 'b'}assert 1 in d# 由于 a 并不是 dict d 的 key，所以下面语句会报错assert 'a' in d NOTE:Even though most containers provide a way to produce every element they contain, that ability does not make them a container but an iterable.Not all containers are necessarily iterable. An example of this is a Bloom filter. Probabilistic data structures like this can be asked whether they contain a certain element, but they are unable to return their individual elements. 2. Iterables如前所述，大部分的 Container 都是可迭代对象，同样很多非 Container 的对象也是可迭代的。在 Container 只能表示有限数据的情况下，一个可迭代对象可能能代表一个无限的数据源。 可迭代对象可以是任何一个可以返回 iterator(迭代器) 的对象，并非一定是一种数据结构。 在 iterator(迭代器)和 iterable(可迭代对象)之间有很明显的区别： 1234567891011x = [1, 2, 3]y = iter(x)next(y)# &gt;&gt; 1next(y)# &gt;&gt; 2type(x)# &gt;&gt; &lt;class 'list'&gt;type(y)# &gt;&gt; &lt;class 'list_iterator'&gt; 如上代码块所示，x 是一个list， 即一个可迭代对象（iterable），而 y 是一个迭代器（iterator） 2.1 实现方法 内置函数iter()实际是映射到了__iter__函数 只要实现了__iter__的对象就是**可迭代对象(Iterable)**，正常情况下，应该返回一个实现了__next__的对象(虽然这个要求不强制)，如果自己实现了__next__，当然也可以返回自己 同时实现了__iter__和__next__的是**迭代器(Iterator)**，当然也是一个可迭代对象了，其中__next__应该在迭代完成后，抛出一个StopIteration异常 for语句会自动处理这个StopIteration异常以便结束for循环 当写出如下代码时： 123x = [1, 2, 3, 4]for i in x: ... 实际上执行了如下动作： 3. iterator其实刚刚提到过， 一个迭代器（iterator）就是同时实现了__iter__和__next__方法的对象，当在该对象上调用内置函数next()时，会产出下一个值。 一个实现了iter方法的对象是可迭代的，一个实现next方法并且是可迭代的对象是迭代器。可以被next()函数调用并不断返回下一个值的对象称为迭代器：Iterator。 迭代器的实例有很多，有的产生有限序列，有的产生无限序列，下面举一个能产生无限序列的例子： 1234from itertools import cyclecolors = cycle(['red', 'white', 'blue'])next(colors)# &gt;&gt; red -&gt; white -&gt; blue -&gt; red -&gt; white -&gt; ... 为了更好地了解迭代器的搭建原理，让我们构建一个生成斐波那契数的迭代器（经典.jpg）： 12345678910111213141516171819from itertools import isliceclass fib: def __init__(self): self.prev = 0 self. curr = 1 def __iter__(self): return self def __next__(self): value = self.curr self.curr = sefl.curr + sefl.prev self.prev = value return valuef = fib()list(islice(f, 0, 10))# &gt;&gt; [1, 1, 2, 3, 5, 8, 13, 21, 34, 55]# Note that this class is both an iterable (because it sports an __iter__() method), and its own iterator (because it has a __next__() method). 请注意，此类既是可迭代的（因为它使用__iter__()方法），又是自己的迭代器（因为它具有__next__()方法）。 Central idea: a lazy factoryFrom the outside, the iterator is like a lazy factory that is idle until you ask it for a value, which is when it starts to buzz and produce a single value, after which it turns idle again. 4. Generator生成器(generator)是一种特殊的迭代器(iterator)，在 Python 中，使用了 yield 的函数被称为生成器(generator) 生成器是一个返回迭代器的函数，只能用于迭代操作，更简单点理解生成器就是一个迭代器。 在调用生成器运行的过程中，每次遇到 yield 时函数会暂停并保存当前所有的运行信息，返回 yield 的值, 并在下一次执行 next() 方法时从当前位置继续运行。 调用一个生成器函数，返回的是一个迭代器对象。 生成器的种类4.1 生成器函数生成器函数会随着时间的推移生成一个数值队列。一般的函数在执行完毕之后会返回一个值然后退出，但是生成器函数会自动挂起，然后重新拾起继续执行，他会利用yield关键字挂起函数，给调用者返回一个值，同时保留了当前的足够多的状态，可以使函数继续执行。 生成器和迭代协议是密切相关的，迭代器都有一个__next__()__成员方法，这个方法要么返回迭代的下一项，要么引起异常结束迭代。 12345678910111213141516171819202122# 函数有了yield之后，函数名+（）就变成了生成器# return在生成器中代表生成器的中止，直接报错# next的作用是唤醒并继续执行# send的作用是唤醒并继续执行，发送一个信息到生成器内部'''生成器'''def create_counter(n): print(&quot;create_counter&quot;) while True: yield n print(&quot;increment n&quot;) n +=1gen = create_counter(2)print(gen)# &lt;generator object create_counter at 0x0000023A1694A938&gt;print(next(gen))# create_counter# 2print(next(gen))# increment n# 3 4.2 生成器表达式生成器表达式来源于迭代和列表解析的组合，生成器和列表解析类似，但是它使用尖括号而不是方括号 1234567891011# 列表解析生成列表[ x ** 3 for x in range(5)]# &gt;&gt; [0, 1, 8, 27, 64]# 生成器表达式(x ** 3 for x in range(5))# &gt;&gt; &lt;generator object &lt;genexpr&gt; at 0x000000000315F678&gt;# 两者之间转换list(x ** 3 for x in range(5))# &gt;&gt; [0, 1, 8, 27, 64] 5. Summary 只要实现了__iter__的对象就是 **可迭代对象(Iterable)**，正常情况下，应该返回一个实现了__next__的对象(虽然这个要求不强制)，如果自己实现了__next__，当然也可以返回自己 凡是可作用于for循环的对象都是 可迭代对象(Iterable) ； 同时实现了__iter__和__next__的是**迭代器(Iterator)**，当然也是一个可迭代对象了，其中__next__应该在迭代完成后，抛出一个StopIteration异常 凡是可作用于next()函数的对象都是 迭代器(Iterator) 类型，它们表示一个惰性计算的序列； 集合数据类型如list、dict、str等是 可迭代对象(Iterable) 但不是 迭代器(Iterator) ，不过可以通过iter()函数获得一个 迭代器(Iterator) 对象。 内置函数iter()实际是映射到了__iter__函数 for语句会自动处理这个StopIteration异常以便结束for循环 window.changyan.api.config({ appid: 'cyvoWBcYh', conf: 'prod_82fb399b42af278fa503f42fe4c11ab1' });","link":"/2021/04/15/python-iteratorFamily/"}],"tags":[{"name":"Templates","slug":"Templates","link":"/tags/Templates/"},{"name":"BlogIssue","slug":"BlogIssue","link":"/tags/BlogIssue/"},{"name":"Essay","slug":"Essay","link":"/tags/Essay/"},{"name":"Pytorch","slug":"Pytorch","link":"/tags/Pytorch/"},{"name":"Dataset","slug":"Dataset","link":"/tags/Dataset/"},{"name":"miniImageNet","slug":"miniImageNet","link":"/tags/miniImageNet/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"Generator","slug":"Generator","link":"/tags/Generator/"},{"name":"Container","slug":"Container","link":"/tags/Container/"},{"name":"Iterable","slug":"Iterable","link":"/tags/Iterable/"},{"name":"Iterator","slug":"Iterator","link":"/tags/Iterator/"}],"categories":[{"name":"Templates","slug":"Templates","link":"/categories/Templates/"},{"name":"Issue","slug":"Issue","link":"/categories/Issue/"},{"name":"Pytorch","slug":"Pytorch","link":"/categories/Pytorch/"},{"name":"DeepLearning","slug":"DeepLearning","link":"/categories/DeepLearning/"},{"name":"Blog","slug":"Templates/Blog","link":"/categories/Templates/Blog/"},{"name":"Python","slug":"Python","link":"/categories/Python/"},{"name":"Dataset","slug":"DeepLearning/Dataset","link":"/categories/DeepLearning/Dataset/"},{"name":"Dataset","slug":"Pytorch/Dataset","link":"/categories/Pytorch/Dataset/"}]}